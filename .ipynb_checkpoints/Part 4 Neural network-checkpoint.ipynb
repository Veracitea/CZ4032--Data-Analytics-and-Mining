{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries \n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import keras \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout \n",
    "#from keras.layers.normalization import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING AND CHANGING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"iris.csv\")\n",
    "df2=pd.read_csv(\"german.csv\")\n",
    "df3=pd.read_csv(\"heart.csv\")\n",
    "df4=pd.read_csv(\"breastCancer.csv\")\n",
    "df5=pd.read_csv(\"wave.csv\")\n",
    "df6=pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "df7=pd.read_csv(\"Placement_Data_Full_Class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "df1['class'] = labelencoder.fit_transform(df1['class'])\n",
    "df2['goodBad'] = labelencoder.fit_transform(df2['goodBad'])\n",
    "df2['checkAccStatus'] = labelencoder.fit_transform(df2['checkAccStatus'])\n",
    "df2['credHist'] = labelencoder.fit_transform(df2['credHist'])\n",
    "df2['purpose'] = labelencoder.fit_transform(df2['purpose'])\n",
    "df2['savAccBond'] = labelencoder.fit_transform(df2['savAccBond'])\n",
    "df2['emplySince'] = labelencoder.fit_transform(df2['emplySince'])\n",
    "df2['personalStatSex'] = labelencoder.fit_transform(df2['personalStatSex'])\n",
    "df2['otherDebtGuar'] = labelencoder.fit_transform(df2['otherDebtGuar'])\n",
    "df2['prpty'] = labelencoder.fit_transform(df2['prpty'])\n",
    "df2['otherInstallPlans'] = labelencoder.fit_transform(df2['otherInstallPlans'])\n",
    "df2['housing'] = labelencoder.fit_transform(df2['housing'])\n",
    "df2['job'] = labelencoder.fit_transform(df2['job'])\n",
    "df2['telephone'] = labelencoder.fit_transform(df2['telephone'])\n",
    "df2['frgnWorker'] = labelencoder.fit_transform(df2['frgnWorker'])\n",
    "df3['class'] = labelencoder.fit_transform(df3['class'])\n",
    "df4['class'] = labelencoder.fit_transform(df4['class'])\n",
    "df4['age'] = labelencoder.fit_transform(df4['age'])\n",
    "df4['menopause'] = labelencoder.fit_transform(df4['menopause'])\n",
    "df4['tumor-size'] = labelencoder.fit_transform(df4['tumor-size'])\n",
    "df4['inv-nodes'] = labelencoder.fit_transform(df4['inv-nodes'])\n",
    "df4['node-caps'] = labelencoder.fit_transform(df4['node-caps'])\n",
    "df4['breast'] = labelencoder.fit_transform(df4['breast'])\n",
    "df4['breast'] = labelencoder.fit_transform(df4['breast'])\n",
    "df4['breast-quad'] = labelencoder.fit_transform(df4['breast-quad'])\n",
    "df4['irradiat'] = labelencoder.fit_transform(df4['irradiat'])\n",
    "df5['class'] = labelencoder.fit_transform(df5['class'])\n",
    "df6['gender'] = labelencoder.fit_transform(df6['gender'])\n",
    "df6['ever_married'] = labelencoder.fit_transform(df6['ever_married'])\n",
    "df6['work_type'] = labelencoder.fit_transform(df6['work_type'])\n",
    "df6['Residence_type'] = labelencoder.fit_transform(df6['Residence_type'])\n",
    "df6['smoking_status'] = labelencoder.fit_transform(df6['smoking_status'])\n",
    "df7['status'] = labelencoder.fit_transform(df7['status'])\n",
    "df7['specialisation'] = labelencoder.fit_transform(df7['specialisation'])\n",
    "df7['workex'] = labelencoder.fit_transform(df7['workex'])\n",
    "df7['degree_t'] = labelencoder.fit_transform(df7['degree_t'])\n",
    "df7['hsc_s'] = labelencoder.fit_transform(df7['hsc_s'])\n",
    "df7['hsc_b'] = labelencoder.fit_transform(df7['hsc_b'])\n",
    "df7['ssc_b'] = labelencoder.fit_transform(df7['ssc_b'])\n",
    "df7['gender'] = labelencoder.fit_transform(df7['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df7.drop([\"salary\",\"sl_no\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>79.33</td>\n",
       "      <td>0</td>\n",
       "      <td>78.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>77.48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0</td>\n",
       "      <td>66.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>85.80</td>\n",
       "      <td>0</td>\n",
       "      <td>73.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.8</td>\n",
       "      <td>0</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>80.60</td>\n",
       "      <td>1</td>\n",
       "      <td>82.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>1</td>\n",
       "      <td>60.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>1</td>\n",
       "      <td>66.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  ssc_p  ssc_b  hsc_p  hsc_b  hsc_s  degree_p  degree_t  workex  \\\n",
       "0         1  67.00      1  91.00      1      1     58.00         2       0   \n",
       "1         1  79.33      0  78.33      1      2     77.48         2       1   \n",
       "2         1  65.00      0  68.00      0      0     64.00         0       0   \n",
       "3         1  56.00      0  52.00      0      2     52.00         2       0   \n",
       "4         1  85.80      0  73.60      0      1     73.30         0       0   \n",
       "..      ...    ...    ...    ...    ...    ...       ...       ...     ...   \n",
       "210       1  80.60      1  82.00      1      1     77.60         0       0   \n",
       "211       1  58.00      1  60.00      1      2     72.00         2       0   \n",
       "212       1  67.00      1  67.00      1      1     73.00         0       1   \n",
       "213       0  74.00      1  66.00      1      1     58.00         0       0   \n",
       "214       1  62.00      0  58.00      1      2     53.00         0       0   \n",
       "\n",
       "     etest_p  specialisation  mba_p  status  \n",
       "0       55.0               1  58.80       1  \n",
       "1       86.5               0  66.28       1  \n",
       "2       75.0               0  57.80       1  \n",
       "3       66.0               1  59.43       0  \n",
       "4       96.8               0  55.50       1  \n",
       "..       ...             ...    ...     ...  \n",
       "210     91.0               0  74.49       1  \n",
       "211     74.0               0  53.62       1  \n",
       "212     59.0               0  69.72       1  \n",
       "213     70.0               1  60.23       1  \n",
       "214     89.0               1  60.22       0  \n",
       "\n",
       "[215 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=df1[[\"sepallength\",\"petalwidth\",\"sepalwidth\",\"petallength\"]]\n",
    "y1=df1[[\"class\"]]\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=25, test_size=0.2, stratify = y1)#25\n",
    "train1 = pd.concat([X1_train, y1_train], axis=1)\n",
    "test1=pd.concat([X1_test, y1_test], axis=1)\n",
    "\n",
    "X2=df2[['checkAccStatus', 'durationMth', 'credHist', 'purpose', 'credAmt',\n",
    "       'savAccBond', 'emplySince', 'instRate', 'personalStatSex',\n",
    "       'otherDebtGuar', 'presResSince', 'prpty', 'age(years)',\n",
    "       'otherInstallPlans', 'housing', 'numExistCreds', 'job',\n",
    "       'numPplMaintain', 'telephone', 'frgnWorker']]\n",
    "y2=df2[[\"goodBad\"]]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=25, test_size=0.2, stratify = y2)#25\n",
    "train2 = pd.concat([X2_train, y2_train], axis=1)\n",
    "test2=pd.concat([X2_test, y2_test], axis=1)\n",
    "\n",
    "X3=df3[['age', 'sex', 'chest pain type', 'resting blood pressure',\n",
    "       'serum cholesterol (mg/dl)', 'resting blood sugar >120mg/dl',\n",
    "       'resting electrocariographic results', 'maximum heart rate received',\n",
    "       'exercise induced angina', 'oldpeak', 'slopePeak', 'numMajorVessels',\n",
    "       'thal']]\n",
    "y3=df3[[\"class\"]]\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, random_state=25, test_size=0.2, stratify = y3)#25\n",
    "train3 = pd.concat([X3_train, y3_train], axis=1)\n",
    "test3=pd.concat([X3_test, y3_test], axis=1)\n",
    "\n",
    "X4=df4[[ 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps',\n",
    "       'deg-malig', 'breast', 'breast-quad', 'irradiat']]\n",
    "y4=df4[['class']]\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, random_state=25, test_size=0.2, stratify = y4)#25\n",
    "train4 = pd.concat([X4_train, y4_train], axis=1)\n",
    "test4=pd.concat([X4_test, y4_test], axis=1)\n",
    "\n",
    "X5=df5[['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
    "       'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20']]\n",
    "y5=df5[[\"class\"]]\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, random_state=25, test_size=0.2, stratify = y5)#25\n",
    "train5 = pd.concat([X5_train, y5_train], axis=1)\n",
    "test5=pd.concat([X5_test, y5_test], axis=1)\n",
    "\n",
    "\n",
    "X6=df6[['id',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'hypertension',\n",
    " 'heart_disease',\n",
    " 'ever_married',\n",
    " 'work_type',\n",
    " 'Residence_type',\n",
    " 'avg_glucose_level',\n",
    " 'bmi',\n",
    " 'smoking_status']]\n",
    "y6=df6[['stroke']]\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6, random_state=25, test_size=0.2, stratify = y6)#25\n",
    "train6 = pd.concat([X6_train, y6_train], axis=1)\n",
    "test6=pd.concat([X6_test, y6_test], axis=1)\n",
    "\n",
    "X7=df7[['gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s',\n",
    "       'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p']]\n",
    "y7=df7[['status']]\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(X7, y7, random_state=25, test_size=0.2, stratify = y7)#25\n",
    "train7 = pd.concat([X7_train, y7_train], axis=1)\n",
    "test7=pd.concat([X7_test, y7_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_p',\n",
       "       'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X7.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7[\"status\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train=np_utils.to_categorical(y1_train,num_classes=3)\n",
    "y1_test=np_utils.to_categorical(y1_test,num_classes=3)\n",
    "\n",
    "\n",
    "y2_train=np_utils.to_categorical(y2_train,num_classes=2)\n",
    "y2_test=np_utils.to_categorical(y2_test,num_classes=2)\n",
    "\n",
    "\n",
    "y3_train=np_utils.to_categorical(y3_train,num_classes=2)\n",
    "y3_test=np_utils.to_categorical(y3_test,num_classes=2)\n",
    "\n",
    "y4_train=np_utils.to_categorical(y4_train,num_classes=2)\n",
    "y4_test=np_utils.to_categorical(y4_test,num_classes=2)\n",
    "\n",
    "y5_train=np_utils.to_categorical(y5_train,num_classes=3)\n",
    "y5_test=np_utils.to_categorical(y5_test,num_classes=3)\n",
    "\n",
    "y6_train=np_utils.to_categorical(y6_train,num_classes=2)\n",
    "y6_test=np_utils.to_categorical(y6_test,num_classes=2)\n",
    "\n",
    "y7_train=np_utils.to_categorical(y7_train,num_classes=2)\n",
    "y7_test=np_utils.to_categorical(y7_test,num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1000,input_dim=4,activation='relu'))\n",
    "model.add(Dense(500,activation='relu'))\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 6ms/step - loss: 0.8482 - accuracy: 0.5583\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.8083\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3505 - accuracy: 0.8250\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.3305 - accuracy: 0.8333\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2831 - accuracy: 0.8667\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2356 - accuracy: 0.8750\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1580 - accuracy: 0.9250\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9250\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1590 - accuracy: 0.9500\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1564 - accuracy: 0.9333\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9833\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.9750\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9833\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9750\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1098 - accuracy: 0.9583\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0715 - accuracy: 0.9833\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0747 - accuracy: 0.9750\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9667\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9667\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0750 - accuracy: 0.9750\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9917\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0704 - accuracy: 0.9750\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0467 - accuracy: 0.9833\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0523 - accuracy: 0.9917\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9917\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0600 - accuracy: 0.9833\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0464 - accuracy: 0.9917\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0507 - accuracy: 0.9917\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0565 - accuracy: 0.9833\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0559 - accuracy: 0.9833\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0506 - accuracy: 0.9917\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9750\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0727 - accuracy: 0.9833\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9833\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0522 - accuracy: 0.9833\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9667\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2476 - accuracy: 0.9083\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.2112 - accuracy: 0.8833\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0858 - accuracy: 0.9833\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1042 - accuracy: 0.9583\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0544 - accuracy: 0.9917\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 0.9917\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0537 - accuracy: 0.9750\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9750\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.0374 - accuracy: 0.9833\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0553 - accuracy: 0.9917\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0443 - accuracy: 0.9917\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0589 - accuracy: 0.9833\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.0641 - accuracy: 0.9750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20411011ac8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X1_train,y1_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the iris dataset 93.33333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(X1_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y1_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the iris dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(1000,input_dim=20,activation='relu'))\n",
    "model2.add(Dense(500,activation='relu'))\n",
    "model2.add(Dense(300,activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(2,activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 81.3232 - accuracy: 0.5625\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.1973 - accuracy: 0.5450\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 5.8552 - accuracy: 0.5475\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 3.7038 - accuracy: 0.5838\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 2.4260 - accuracy: 0.5725\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 1.4299 - accuracy: 0.6062\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 1.1909 - accuracy: 0.5863\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6826 - accuracy: 0.6712\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6228 - accuracy: 0.7000\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6109 - accuracy: 0.7000\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6151 - accuracy: 0.7000\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6086 - accuracy: 0.7000\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6113 - accuracy: 0.7000\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6105 - accuracy: 0.7000\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6122 - accuracy: 0.7000\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.7000\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.7000\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.7000\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.7000\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6095 - accuracy: 0.7000\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6088 - accuracy: 0.7000\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6085 - accuracy: 0.7000\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.7000\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.7000\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.7000\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.7000\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6086 - accuracy: 0.7000\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6066 - accuracy: 0.7000\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.7000\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6102 - accuracy: 0.7000\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6087 - accuracy: 0.7000\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6089 - accuracy: 0.7000\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6106 - accuracy: 0.7000\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6096 - accuracy: 0.7000\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6101 - accuracy: 0.7000\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.7000\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6075 - accuracy: 0.7000\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6102 - accuracy: 0.7000\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6079 - accuracy: 0.7000\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6118 - accuracy: 0.7000\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6077 - accuracy: 0.7000\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6105 - accuracy: 0.7000\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6094 - accuracy: 0.7000\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6099 - accuracy: 0.7000\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6083 - accuracy: 0.7000\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6091 - accuracy: 0.7000\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6092 - accuracy: 0.7000\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.7000\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.6098 - accuracy: 0.7000\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6389 - accuracy: 0.6938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x204184f12c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X2_train,y2_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the german dataset 70.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       140\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.35      0.50      0.41       200\n",
      "weighted avg       0.49      0.70      0.58       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "prediction=model2.predict(X2_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y2_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the german dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Dense(1000,input_dim=13,activation='relu'))\n",
    "model3.add(Dense(500,activation='relu'))\n",
    "model3.add(Dense(300,activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(2,activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 10.5292 - accuracy: 0.4583\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 3.1528 - accuracy: 0.5880\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2501 - accuracy: 0.5648\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6390 - accuracy: 0.5926\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.9262 - accuracy: 0.6574\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.9905 - accuracy: 0.6250\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.8412 - accuracy: 0.5926\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6349 - accuracy: 0.6759\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.6114 - accuracy: 0.6806\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.6944\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.7083\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6100 - accuracy: 0.6852\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.6034 - accuracy: 0.6620\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 0.5558 - accuracy: 0.7083\n",
      "Epoch 15/50\n",
      " 1/11 [=>............................] - ETA: 0s - loss: 0.5537 - accuracy: 0.7500"
     ]
    }
   ],
   "source": [
    "model3.fit(X3_train,y3_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model3.predict(X3_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y3_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the heart dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=Sequential()\n",
    "model4.add(Dense(1000,input_dim=9,activation='relu'))\n",
    "model4.add(Dense(500,activation='relu'))\n",
    "model4.add(Dense(300,activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(2,activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit(X4_train,y4_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model4.predict(X4_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y4_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the cancer dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=Sequential()\n",
    "model5.add(Dense(1000,input_dim=21,activation='relu'))\n",
    "model5.add(Dense(500,activation='relu'))\n",
    "model5.add(Dense(300,activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(3,activation='softmax'))\n",
    "model5.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.fit(X5_train,y5_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model5.predict(X5_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y5_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the wave dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6=Sequential()\n",
    "model6.add(Dense(1000,input_dim=11,activation='relu'))\n",
    "model6.add(Dense(500,activation='relu'))\n",
    "model6.add(Dense(300,activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(2,activation='softmax'))\n",
    "model6.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.fit(X6_train,y6_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model6.predict(X6_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y6_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the stroke dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7=Sequential()\n",
    "model7.add(Dense(1000,input_dim=12,activation='relu'))\n",
    "model7.add(Dense(500,activation='relu'))\n",
    "model7.add(Dense(300,activation='relu'))\n",
    "model7.add(Dropout(0.2))\n",
    "model7.add(Dense(2,activation='softmax'))\n",
    "model7.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.fit(X7_train,y7_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model7.predict(X7_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y7_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the placement dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "94c38aa216cb19f74293236aacf8c039d75912cab4e786edf53a4f1451d3d752"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
