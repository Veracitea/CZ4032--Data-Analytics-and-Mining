{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yarc import CBA\n",
    "from yarc.Structure import TransactionDB\n",
    "from yarc.Mine_Classi_Alg.generating_CARS import ClassAssocationRule, Antecedent, Consequent, top_rules, CARlist\n",
    "from yarc.Mine_Classi_Alg.m2classi import M2Classi\n",
    "from yarc.Mine_Classi_Alg.predictor import Predictor\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yarc.qcba.data_structures import *\n",
    "from yarc.qcba import *\n",
    "from yarc.qcba.transformation import *\n",
    "import Orange\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from Orange.data.pandas_compat import table_from_frame,table_to_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretiseRule(X):\n",
    "    temp = Orange.data.Table(X)\n",
    "    disc = Orange.preprocess.Discretize()\n",
    "    disc.method = Orange.preprocess.discretize.EqualFreq(n=3)\n",
    "    d_temp = disc(temp)\n",
    "    X= table_to_frame(d_temp)\n",
    "    return X\n",
    "\n",
    "def runQCBA(X,y,target):\n",
    "    X = discretiseRule(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=25, test_size=0.2, stratify = y)#25\n",
    "    train = pd.concat([X_train, y_train], axis=1)\n",
    "    test=pd.concat([X_test, y_test], axis=1)\n",
    "    \n",
    "    txns = TransactionDB.from_DataFrame(train, target=target)\n",
    "    txnstest = TransactionDB.from_DataFrame(test, target=target)\n",
    "    \n",
    "    cba=CBA()\n",
    "    cba.fit(txns)\n",
    "    acc1=cba.rule_model_accuracy(txnstest) #Part 2 model\n",
    "    # get the best association rules\n",
    "    rules = top_rules(txns.string_representation)\n",
    "    # convert them to class association rules\n",
    "    cars = CARlist(rules)\n",
    "    predictor = M2Classi(cars, txns).build()\n",
    "    acc2= predictor.test_transactions(txnstest)\n",
    "    ds = test.reset_index() #test set of undis\n",
    "    quant_dataset = QuantitativeDataFrame(ds)\n",
    "    \n",
    "    Y = ds[target]\n",
    "    rules=cba.pre.rules\n",
    "    quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "    \n",
    "    rules2 = predictor.rules\n",
    "    quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "    \n",
    "    qcba_transformation = QCBATransformation(quant_dataset)\n",
    "    refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "    literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "    trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "    pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)\n",
    "    refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "    literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "    trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "    pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)\n",
    "    q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "    acc3=q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model\n",
    "    q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "    acc4=q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model(top rules)\n",
    "    print(\"Accuracy of CBA:\",acc1)\n",
    "    print(\"Accuracy of CBA (Top k):\",acc2)\n",
    "    print(\"Accuracy of QCBA:\",acc3)\n",
    "    print(\"Accuracy of QCBA (Top k):\",acc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBA: 0.9\n",
      "Accuracy of CBA (Top k): 0.9\n",
      "Accuracy of QCBA: 0.9333333333333333\n",
      "Accuracy of QCBA (Top k): 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "iris = pd.read_csv ('iris.csv')\n",
    "X=iris[[\"sepallength\",\"petalwidth\",\"sepalwidth\",\"petallength\"]]\n",
    "y=iris[[\"class\"]]\n",
    "runQCBA(X,y,\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBA: 0.764\n",
      "Accuracy of CBA (Top k): 0.797\n",
      "Accuracy of QCBA: 0.768\n",
      "Accuracy of QCBA (Top k): 0.81\n"
     ]
    }
   ],
   "source": [
    "wave = pd.read_csv ('wave.csv')\n",
    "wave = wave.dropna()\n",
    "X=wave[['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20']]\n",
    "y=wave[[\"class\"]]\n",
    "runQCBA(X,y,\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBA: 0.8148148148148148\n",
      "Accuracy of CBA (Top k): 0.7777777777777778\n",
      "Accuracy of QCBA: 0.9259259259259259\n",
      "Accuracy of QCBA (Top k): 0.8703703703703703\n"
     ]
    }
   ],
   "source": [
    "heart = pd.read_csv ('heart.csv')\n",
    "heart = heart.dropna()\n",
    "X=heart[[\"age\", \"sex\", \"chest pain type\", \"resting blood pressure\", \"serum cholesterol (mg/dl)\", \"resting blood sugar >120mg/dl\",\"resting electrocariographic results\",\"maximum heart rate received\",\"exercise induced angina\", \"oldpeak\",\"slopePeak\", \"numMajorVessels\",\"thal\"]]\n",
    "y=heart[[\"class\"]]\n",
    "runQCBA(X,y,\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1817: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBA: 0.6491228070175439\n",
      "Accuracy of CBA (Top k): 0.6666666666666666\n",
      "Accuracy of QCBA: 0.8070175438596491\n",
      "Accuracy of QCBA (Top k): 0.7894736842105263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "breastCancer = pd.read_csv ('breastCancer.csv')\n",
    "breastCancer = breastCancer.dropna()\n",
    "X=breastCancer[[\"menopause\", \"age\", \"tumor-size\", \"inv-nodes\", \"node-caps\",\"deg-malig\",\"breast\",\"breast-quad\",\"irradiat\"]]\n",
    "#encoding the normal data\n",
    "for col in [\"menopause\",\"node-caps\",\"breast\",\"breast-quad\",\"irradiat\"]:\n",
    "   X[col] = LabelEncoder().fit_transform(X[col])\n",
    "#encoding the ordinal data #Ordinal Encoder not working so i just hardcoded first\n",
    "ordinalData = [\"age\",\"tumor-size\",\"inv-nodes\"]\n",
    "for i in ordinalData:\n",
    "   columns = X[i].unique()\n",
    "   columns.sort() #sorting the labels\n",
    "   for j in range(len(columns)):\n",
    "      X.loc[X[i]==columns[j],i] = j\n",
    "y=breastCancer[[\"class\"]]\n",
    "runQCBA(X,y,\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBA: 0.7\n",
      "Accuracy of CBA (Top k): 0.73\n",
      "Accuracy of QCBA: 0.745\n",
      "Accuracy of QCBA (Top k): 0.76\n"
     ]
    }
   ],
   "source": [
    "german = pd.read_csv ('german.csv')\n",
    "german = german.dropna()\n",
    "X=german[[\"checkAccStatus\", \"durationMth\", \"credHist\", \"purpose\", \"credAmt\",\"savAccBond\",\"emplySince\",\"instRate\",\"personalStatSex\",\"otherDebtGuar\",\"presResSince\",\"prpty\",\"age(years)\",\"otherInstallPlans\",\"housing\",\"numExistCreds\",\"job\",\"numPplMaintain\",\"telephone\",\"frgnWorker\"]]\n",
    "for col in ['checkAccStatus','credHist','purpose','savAccBond','emplySince','personalStatSex','otherDebtGuar','prpty','otherInstallPlans','housing','job','telephone','frgnWorker']:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "y=german[[\"goodBad\"]]\n",
    "runQCBA(X,y,\"goodBad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University Student Placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBA: 0.7674418604651163\n",
      "Accuracy of CBA (Top k): 0.7674418604651163\n",
      "Accuracy of QCBA: 0.9069767441860465\n",
      "Accuracy of QCBA (Top k): 0.8604651162790697\n"
     ]
    }
   ],
   "source": [
    "campusPlacement = pd.read_csv(\"Placement_Data_Full_Class.csv\")\n",
    "campusPlacement.head()\n",
    "campusPlacement = campusPlacement.drop(['salary'],1)\n",
    "campusPlacement = campusPlacement.dropna()\n",
    "X = campusPlacement[['sl_no', 'gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p']]\n",
    "#creating a function to encode categorical features into numerical\n",
    "for col in ['gender','ssc_b','hsc_b','hsc_s','degree_t','workex','specialisation']:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "y=campusPlacement[['status']]\n",
    "runQCBA(X,y,\"status\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n",
      "C:\\Users\\theco\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of CBA: 0.534698521046644\n",
      "Accuracy of CBA (Top k): 0.534698521046644\n",
      "Accuracy of QCBA: 0.534698521046644\n",
      "Accuracy of QCBA (Top k): 0.8623435722411832\n"
     ]
    }
   ],
   "source": [
    "stroke = pd.read_csv('healthcare-dataset-stroke-data.csv')\n",
    "stroke = stroke.drop(['id'],1)\n",
    "stroke = stroke.dropna()\n",
    "X=stroke[[\"gender\", \"age\", \"heart_disease\", \"ever_married\", \"work_type\",\"Residence_type\",\"avg_glucose_level\",\"bmi\",\"smoking_status\"]]\n",
    "#encoding the normal data\n",
    "for col in [\"gender\",\"ever_married\",\"work_type\",\"Residence_type\", \"smoking_status\"]:\n",
    "   X[col] = LabelEncoder().fit_transform(X[col])\n",
    "y=stroke[[\"stroke\"]]\n",
    "runQCBA(X,y,\"stroke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txnstest = TransactionDB.from_DataFrame(test, target=\"class\") \n",
    "\n",
    "df2=pd.read_csv(\"german.csv\")\n",
    "df3=pd.read_csv(\"heart.csv\")\n",
    "df4=pd.read_csv(\"breastCancer.csv\")\n",
    "df5=pd.read_csv(\"wave.csv\")\n",
    "df6=pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "df7=pd.read_csv(\"Placement_Data_Full_Class.csv\")\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "df2['goodBad'] = labelencoder.fit_transform(df2['goodBad'])\n",
    "df2['checkAccStatus'] = labelencoder.fit_transform(df2['checkAccStatus'])\n",
    "df2['credHist'] = labelencoder.fit_transform(df2['credHist'])\n",
    "df2['purpose'] = labelencoder.fit_transform(df2['purpose'])\n",
    "df2['savAccBond'] = labelencoder.fit_transform(df2['savAccBond'])\n",
    "df2['emplySince'] = labelencoder.fit_transform(df2['emplySince'])\n",
    "df2['personalStatSex'] = labelencoder.fit_transform(df2['personalStatSex'])\n",
    "df2['otherDebtGuar'] = labelencoder.fit_transform(df2['otherDebtGuar'])\n",
    "df2['prpty'] = labelencoder.fit_transform(df2['prpty'])\n",
    "df2['otherInstallPlans'] = labelencoder.fit_transform(df2['otherInstallPlans'])\n",
    "df2['housing'] = labelencoder.fit_transform(df2['housing'])\n",
    "df2['job'] = labelencoder.fit_transform(df2['job'])\n",
    "df2['telephone'] = labelencoder.fit_transform(df2['telephone'])\n",
    "df2['frgnWorker'] = labelencoder.fit_transform(df2['frgnWorker'])\n",
    "df4['age'] = labelencoder.fit_transform(df4['age'])\n",
    "df4['menopause'] = labelencoder.fit_transform(df4['menopause'])\n",
    "df4['tumor-size'] = labelencoder.fit_transform(df4['tumor-size'])\n",
    "df4['inv-nodes'] = labelencoder.fit_transform(df4['inv-nodes'])\n",
    "df4['node-caps'] = labelencoder.fit_transform(df4['node-caps'])\n",
    "df4['breast'] = labelencoder.fit_transform(df4['breast'])\n",
    "df4['breast'] = labelencoder.fit_transform(df4['breast'])\n",
    "df4['breast-quad'] = labelencoder.fit_transform(df4['breast-quad'])\n",
    "df4['irradiat'] = labelencoder.fit_transform(df4['irradiat'])\n",
    "df6['gender'] = labelencoder.fit_transform(df6['gender'])\n",
    "df6['ever_married'] = labelencoder.fit_transform(df6['ever_married'])\n",
    "df6['work_type'] = labelencoder.fit_transform(df6['work_type'])\n",
    "df6['Residence_type'] = labelencoder.fit_transform(df6['Residence_type'])\n",
    "df6['smoking_status'] = labelencoder.fit_transform(df6['smoking_status'])\n",
    "df7['specialisation'] = labelencoder.fit_transform(df7['specialisation'])\n",
    "df7['workex'] = labelencoder.fit_transform(df7['workex'])\n",
    "df7['degree_t'] = labelencoder.fit_transform(df7['degree_t'])\n",
    "df7['hsc_s'] = labelencoder.fit_transform(df7['hsc_s'])\n",
    "df7['hsc_b'] = labelencoder.fit_transform(df7['hsc_b'])\n",
    "df7['ssc_b'] = labelencoder.fit_transform(df7['ssc_b'])\n",
    "df7['gender'] = labelencoder.fit_transform(df7['gender'])\n",
    "df7=df7.drop([\"salary\",\"sl_no\"], axis=1)\n",
    "\n",
    "\n",
    "X2=df2[['checkAccStatus', 'durationMth', 'credHist', 'purpose', 'credAmt',\n",
    "       'savAccBond', 'emplySince', 'instRate', 'personalStatSex',\n",
    "       'otherDebtGuar', 'presResSince', 'prpty', 'age(years)',\n",
    "       'otherInstallPlans', 'housing', 'numExistCreds', 'job',\n",
    "       'numPplMaintain', 'telephone', 'frgnWorker']]\n",
    "X2 = discretiseRule(X2)\n",
    "y2=df2[[\"goodBad\"]]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=25, test_size=0.2, stratify = y2)#25\n",
    "train2 = pd.concat([X2_train, y2_train], axis=1)\n",
    "test2=pd.concat([X2_test, y2_test], axis=1)\n",
    "txns2 = TransactionDB.from_DataFrame(train2, target=\"goodBad\")\n",
    "txnstest2 = TransactionDB.from_DataFrame(test2, target=\"goodBad\") \n",
    "\n",
    "X3=df3[['age', 'sex', 'chest pain type', 'resting blood pressure',\n",
    "       'serum cholesterol (mg/dl)', 'resting blood sugar >120mg/dl',\n",
    "       'resting electrocariographic results', 'maximum heart rate received',\n",
    "       'exercise induced angina', 'oldpeak', 'slopePeak', 'numMajorVessels',\n",
    "       'thal']]\n",
    "X3 = discretiseRule(X3)\n",
    "y3=df3[[\"class\"]]\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, random_state=25, test_size=0.2, stratify = y3)#25\n",
    "train3 = pd.concat([X3_train, y3_train], axis=1)\n",
    "test3=pd.concat([X3_test, y3_test], axis=1)\n",
    "txns3 = TransactionDB.from_DataFrame(train3, target=\"class\")\n",
    "txnstest3 = TransactionDB.from_DataFrame(test3, target=\"class\") \n",
    "\n",
    "X4=df4[[ 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps',\n",
    "       'deg-malig', 'breast', 'breast-quad', 'irradiat']]\n",
    "X4 = discretiseRule(X4)\n",
    "y4=df4[['class']]\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, random_state=25, test_size=0.2, stratify = y4)#25\n",
    "train4 = pd.concat([X4_train, y4_train], axis=1)\n",
    "test4=pd.concat([X4_test, y4_test], axis=1)\n",
    "txns4 = TransactionDB.from_DataFrame(train4, target=\"class\")\n",
    "txnstest4 = TransactionDB.from_DataFrame(test4, target=\"class\") \n",
    "\n",
    "X5=df5[['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
    "       'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20']]\n",
    "X5 = discretiseRule(X5)\n",
    "y5=df5[[\"class\"]]\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, random_state=25, test_size=0.2, stratify = y5)#25\n",
    "train5 = pd.concat([X5_train, y5_train], axis=1)\n",
    "test5=pd.concat([X5_test, y5_test], axis=1)\n",
    "txns5 = TransactionDB.from_DataFrame(train5, target=\"class\")\n",
    "txnstest5 = TransactionDB.from_DataFrame(test5, target=\"class\") \n",
    "\n",
    "\n",
    "X6=df6[['id',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'hypertension',\n",
    " 'heart_disease',\n",
    " 'ever_married',\n",
    " 'work_type',\n",
    " 'Residence_type',\n",
    " 'avg_glucose_level',\n",
    " 'bmi',\n",
    " 'smoking_status']]\n",
    "X6 = discretiseRule(X6)\n",
    "y6=df6[['stroke']]\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6, random_state=25, test_size=0.2, stratify = y6)#25\n",
    "train6 = pd.concat([X6_train, y6_train], axis=1)\n",
    "test6=pd.concat([X6_test, y6_test], axis=1)\n",
    "txns6 = TransactionDB.from_DataFrame(train6, target=\"stroke\")\n",
    "txnstest6 = TransactionDB.from_DataFrame(test6, target=\"stroke\") \n",
    "\n",
    "X7=df7[['gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s',\n",
    "       'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p']]\n",
    "X7= discretiseRule(X7)\n",
    "y7=df7[['status']]\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(X7, y7, random_state=25, test_size=0.2, stratify = y7)#25\n",
    "train7 = pd.concat([X7_train, y7_train], axis=1)\n",
    "test7=pd.concat([X7_test, y7_test], axis=1)\n",
    "txns7 = TransactionDB.from_DataFrame(train7, target=\"status\")\n",
    "txnstest7 = TransactionDB.from_DataFrame(test7, target=\"status\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba = CBA()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba.fit(txns)\n",
    "cba.rule_model_accuracy(txnstest) #Part 2 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the best association rules\n",
    "rules = top_rules(txns.string_representation)\n",
    "\n",
    "# convert them to class association rules\n",
    "cars = CARlist(rules)\n",
    "\n",
    "predictor = M2Classi(cars, txns).build()\n",
    "\n",
    "accuracy = predictor.test_transactions(txnstest)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = test.reset_index() #test set of undis\n",
    "quant_dataset = QuantitativeDataFrame(ds)\n",
    "Y = ds[\"class\"]\n",
    "quant_dataset.dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules=cba.pre.rules\n",
    "quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules2 = predictor.rules\n",
    "quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "rules2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcba_transformation = QCBATransformation(quant_dataset)\n",
    "quant_dataset.dataframe[\"class\"]\n",
    "quant_dataset._QuantitativeDataFrame__preprocessed_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba=CBA()\n",
    "cba.fit(txns2)\n",
    "acc1=cba.rule_model_accuracy(txnstest2) #Part 2 model\n",
    "# get the best association rules\n",
    "rules = top_rules(txns2.string_representation)\n",
    "# convert them to class association rules\n",
    "cars = CARlist(rules)\n",
    "predictor = M2Classi(cars, txns2).build()\n",
    "acc2= predictor.test_transactions(txnstest2)\n",
    "ds = test2.reset_index() #test set of undis\n",
    "quant_dataset = QuantitativeDataFrame(ds)\n",
    "Y = ds[\"goodBad\"]\n",
    "rules=cba.pre.rules\n",
    "quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "rules2 = predictor.rules\n",
    "quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "qcba_transformation = QCBATransformation(quant_dataset)\n",
    "refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)\n",
    "refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)\n",
    "q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "acc3=q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model\n",
    "q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "acc4=q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model(top rules)\n",
    "print(acc1,acc2,acc3,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba=CBA()\n",
    "cba.fit(txns3)\n",
    "acc1=cba.rule_model_accuracy(txnstest3) #Part 2 model\n",
    "# get the best association rules\n",
    "rules = top_rules(txns3.string_representation)\n",
    "# convert them to class association rules\n",
    "cars = CARlist(rules)\n",
    "predictor = M2Classi(cars, txns3).build()\n",
    "acc2= predictor.test_transactions(txnstest3)\n",
    "ds = test3.reset_index() #test set of undis\n",
    "quant_dataset = QuantitativeDataFrame(ds)\n",
    "Y = ds[\"class\"]\n",
    "rules=cba.pre.rules\n",
    "quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "rules2 = predictor.rules\n",
    "quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "qcba_transformation = QCBATransformation(quant_dataset)\n",
    "refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)\n",
    "refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)\n",
    "q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "acc3=q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model\n",
    "q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "acc4=q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model(top rules)\n",
    "print(acc1,acc2,acc3,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba=CBA()\n",
    "cba.fit(txns4)\n",
    "acc1=cba.rule_model_accuracy(txnstest4) #Part 2 model\n",
    "# get the best association rules\n",
    "rules = top_rules(txns4.string_representation)\n",
    "# convert them to class association rules\n",
    "cars = CARlist(rules)\n",
    "predictor = M2Classi(cars, txns4).build()\n",
    "acc2= predictor.test_transactions(txnstest4)\n",
    "ds = test4.reset_index() #test set of undis\n",
    "quant_dataset = QuantitativeDataFrame(ds)\n",
    "Y = ds[\"class\"]\n",
    "rules=cba.pre.rules\n",
    "quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "rules2 = predictor.rules\n",
    "quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "qcba_transformation = QCBATransformation(quant_dataset)\n",
    "refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)\n",
    "refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)\n",
    "q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "acc3=q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model\n",
    "q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "acc4=q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model(top rules)\n",
    "print(acc1,acc2,acc3,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba=CBA()\n",
    "cba.fit(txns5)\n",
    "acc1=cba.rule_model_accuracy(txnstest5) #Part 2 model\n",
    "# get the best association rules\n",
    "rules = top_rules(txns5.string_representation)\n",
    "# convert them to class association rules\n",
    "cars = CARlist(rules)\n",
    "predictor = M2Classi(cars, txns5).build()\n",
    "acc2= predictor.test_transactions(txnstest5)\n",
    "ds = test5.reset_index() #test set of undis\n",
    "quant_dataset = QuantitativeDataFrame(ds)\n",
    "Y = ds[\"class\"]\n",
    "rules=cba.pre.rules\n",
    "quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "rules2 = predictor.rules\n",
    "quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "qcba_transformation = QCBATransformation(quant_dataset)\n",
    "refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)\n",
    "refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)\n",
    "q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "acc3=q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model\n",
    "q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "acc4=q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model(top rules)\n",
    "print(acc1,acc2,acc3,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba=CBA()\n",
    "cba.fit(txns6)\n",
    "acc1=cba.rule_model_accuracy(txnstest6) #Part 2 model\n",
    "# get the best association rules\n",
    "rules = top_rules(txns6.string_representation)\n",
    "# convert them to class association rules\n",
    "cars = CARlist(rules)\n",
    "predictor = M2Classi(cars, txns6).build()\n",
    "acc2= predictor.test_transactions(txnstest6)\n",
    "ds = test6.reset_index() #test set of undis\n",
    "quant_dataset = QuantitativeDataFrame(ds)\n",
    "Y = ds[\"stroke\"]\n",
    "rules=cba.pre.rules\n",
    "quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "rules2 = predictor.rules\n",
    "quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "qcba_transformation = QCBATransformation(quant_dataset)\n",
    "refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)\n",
    "refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)\n",
    "q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "acc3=q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model\n",
    "q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "acc4=q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model(top rules)\n",
    "print(acc1,acc2,acc3,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cba=CBA()\n",
    "cba.fit(txns7)\n",
    "acc1=cba.rule_model_accuracy(txnstest7) #Part 2 model\n",
    "# get the best association rules\n",
    "rules = top_rules(txns7.string_representation)\n",
    "# convert them to class association rules\n",
    "cars = CARlist(rules)\n",
    "predictor = M2Classi(cars, txns7).build()\n",
    "acc2= predictor.test_transactions(txnstest7)\n",
    "ds = test7.reset_index() #test set of undis\n",
    "quant_dataset = QuantitativeDataFrame(ds)\n",
    "Y = ds[\"status\"]\n",
    "rules=cba.pre.rules\n",
    "quant_rules = [ QuantitativeCAR(r) for r in rules ] #rules of undis\n",
    "rules2 = predictor.rules\n",
    "quant_rules2 = [ QuantitativeCAR(r) for r in rules2 ] #rules of undis\n",
    "qcba_transformation = QCBATransformation(quant_dataset)\n",
    "refitted_rules = qcba_transformation.refitter.transform(quant_rules)\n",
    "literal_pruned_rules = qcba_transformation.literal_pruner.transform(refitted_rules)\n",
    "trimmed_rules = qcba_transformation.trimmer.transform(literal_pruned_rules)\n",
    "pruned_rules, default_class = qcba_transformation.post_pruner.transform(trimmed_rules)\n",
    "refitted_rules2 = qcba_transformation.refitter.transform(quant_rules2)\n",
    "literal_pruned_rules2 = qcba_transformation.literal_pruner.transform(refitted_rules2)\n",
    "trimmed_rules2 = qcba_transformation.trimmer.transform(literal_pruned_rules2)\n",
    "pruned_rules2, default_class2 = qcba_transformation.post_pruner.transform(trimmed_rules2)\n",
    "q_clf2 = QuantitativeClassifier(pruned_rules, default_class)\n",
    "acc3=q_clf2.rule_model_accuracy(quant_dataset, Y) #Part 5 model\n",
    "q_clf1 = QuantitativeClassifier(pruned_rules2, default_class2)\n",
    "acc4=q_clf1.rule_model_accuracy(quant_dataset, Y) #Part 5 model(top rules)\n",
    "print(acc1,acc2,acc3,acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
