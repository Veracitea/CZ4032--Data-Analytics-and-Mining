{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORT MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries \n",
    "import keras \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense,Activation,Dropout \n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING AND CHANGING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"iris2.csv\")\n",
    "df2=pd.read_csv(\"german.csv\")\n",
    "df3=pd.read_csv(\"heart.csv\")\n",
    "df4=pd.read_csv(\"breastCancer.csv\")\n",
    "df5=pd.read_csv(\"wave.csv\")\n",
    "df6=pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "df7=pd.read_csv(\"Placement_Data_Full_Class.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "df1['class'] = labelencoder.fit_transform(df1['class'])\n",
    "df2['goodBad'] = labelencoder.fit_transform(df2['goodBad'])\n",
    "df2['checkAccStatus'] = labelencoder.fit_transform(df2['checkAccStatus'])\n",
    "df2['credHist'] = labelencoder.fit_transform(df2['credHist'])\n",
    "df2['purpose'] = labelencoder.fit_transform(df2['purpose'])\n",
    "df2['savAccBond'] = labelencoder.fit_transform(df2['savAccBond'])\n",
    "df2['emplySince'] = labelencoder.fit_transform(df2['emplySince'])\n",
    "df2['personalStatSex'] = labelencoder.fit_transform(df2['personalStatSex'])\n",
    "df2['otherDebtGuar'] = labelencoder.fit_transform(df2['otherDebtGuar'])\n",
    "df2['prpty'] = labelencoder.fit_transform(df2['prpty'])\n",
    "df2['otherInstallPlans'] = labelencoder.fit_transform(df2['otherInstallPlans'])\n",
    "df2['housing'] = labelencoder.fit_transform(df2['housing'])\n",
    "df2['job'] = labelencoder.fit_transform(df2['job'])\n",
    "df2['telephone'] = labelencoder.fit_transform(df2['telephone'])\n",
    "df2['frgnWorker'] = labelencoder.fit_transform(df2['frgnWorker'])\n",
    "df3['class'] = labelencoder.fit_transform(df3['class'])\n",
    "df4['class'] = labelencoder.fit_transform(df4['class'])\n",
    "df4['age'] = labelencoder.fit_transform(df4['age'])\n",
    "df4['menopause'] = labelencoder.fit_transform(df4['menopause'])\n",
    "df4['tumor-size'] = labelencoder.fit_transform(df4['tumor-size'])\n",
    "df4['inv-nodes'] = labelencoder.fit_transform(df4['inv-nodes'])\n",
    "df4['node-caps'] = labelencoder.fit_transform(df4['node-caps'])\n",
    "df4['breast'] = labelencoder.fit_transform(df4['breast'])\n",
    "df4['breast'] = labelencoder.fit_transform(df4['breast'])\n",
    "df4['breast-quad'] = labelencoder.fit_transform(df4['breast-quad'])\n",
    "df4['irradiat'] = labelencoder.fit_transform(df4['irradiat'])\n",
    "df5['class'] = labelencoder.fit_transform(df5['class'])\n",
    "df6['gender'] = labelencoder.fit_transform(df6['gender'])\n",
    "df6['ever_married'] = labelencoder.fit_transform(df6['ever_married'])\n",
    "df6['work_type'] = labelencoder.fit_transform(df6['work_type'])\n",
    "df6['Residence_type'] = labelencoder.fit_transform(df6['Residence_type'])\n",
    "df6['smoking_status'] = labelencoder.fit_transform(df6['smoking_status'])\n",
    "df7['status'] = labelencoder.fit_transform(df7['status'])\n",
    "df7['specialisation'] = labelencoder.fit_transform(df7['specialisation'])\n",
    "df7['workex'] = labelencoder.fit_transform(df7['workex'])\n",
    "df7['degree_t'] = labelencoder.fit_transform(df7['degree_t'])\n",
    "df7['hsc_s'] = labelencoder.fit_transform(df7['hsc_s'])\n",
    "df7['hsc_b'] = labelencoder.fit_transform(df7['hsc_b'])\n",
    "df7['ssc_b'] = labelencoder.fit_transform(df7['ssc_b'])\n",
    "df7['gender'] = labelencoder.fit_transform(df7['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df7.drop([\"salary\",\"sl_no\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>ssc_p</th>\n",
       "      <th>ssc_b</th>\n",
       "      <th>hsc_p</th>\n",
       "      <th>hsc_b</th>\n",
       "      <th>hsc_s</th>\n",
       "      <th>degree_p</th>\n",
       "      <th>degree_t</th>\n",
       "      <th>workex</th>\n",
       "      <th>etest_p</th>\n",
       "      <th>specialisation</th>\n",
       "      <th>mba_p</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1</td>\n",
       "      <td>91.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>58.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>79.33</td>\n",
       "      <td>0</td>\n",
       "      <td>78.33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>77.48</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0</td>\n",
       "      <td>66.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>65.00</td>\n",
       "      <td>0</td>\n",
       "      <td>68.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>56.00</td>\n",
       "      <td>0</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>85.80</td>\n",
       "      <td>0</td>\n",
       "      <td>73.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.8</td>\n",
       "      <td>0</td>\n",
       "      <td>55.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1</td>\n",
       "      <td>80.60</td>\n",
       "      <td>1</td>\n",
       "      <td>82.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>74.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>1</td>\n",
       "      <td>60.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>53.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1</td>\n",
       "      <td>67.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "      <td>69.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>74.00</td>\n",
       "      <td>1</td>\n",
       "      <td>66.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1</td>\n",
       "      <td>62.00</td>\n",
       "      <td>0</td>\n",
       "      <td>58.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>53.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "      <td>60.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>215 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  ssc_p  ssc_b  hsc_p  hsc_b  hsc_s  degree_p  degree_t  workex  \\\n",
       "0         1  67.00      1  91.00      1      1     58.00         2       0   \n",
       "1         1  79.33      0  78.33      1      2     77.48         2       1   \n",
       "2         1  65.00      0  68.00      0      0     64.00         0       0   \n",
       "3         1  56.00      0  52.00      0      2     52.00         2       0   \n",
       "4         1  85.80      0  73.60      0      1     73.30         0       0   \n",
       "..      ...    ...    ...    ...    ...    ...       ...       ...     ...   \n",
       "210       1  80.60      1  82.00      1      1     77.60         0       0   \n",
       "211       1  58.00      1  60.00      1      2     72.00         2       0   \n",
       "212       1  67.00      1  67.00      1      1     73.00         0       1   \n",
       "213       0  74.00      1  66.00      1      1     58.00         0       0   \n",
       "214       1  62.00      0  58.00      1      2     53.00         0       0   \n",
       "\n",
       "     etest_p  specialisation  mba_p  status  \n",
       "0       55.0               1  58.80       1  \n",
       "1       86.5               0  66.28       1  \n",
       "2       75.0               0  57.80       1  \n",
       "3       66.0               1  59.43       0  \n",
       "4       96.8               0  55.50       1  \n",
       "..       ...             ...    ...     ...  \n",
       "210     91.0               0  74.49       1  \n",
       "211     74.0               0  53.62       1  \n",
       "212     59.0               0  69.72       1  \n",
       "213     70.0               1  60.23       1  \n",
       "214     89.0               1  60.22       0  \n",
       "\n",
       "[215 rows x 13 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=df1[[\"sepallength\",\"petalwidth\",\"sepalwidth\",\"petallength\"]]\n",
    "y1=df1[[\"class\"]]\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, random_state=25, test_size=0.2, stratify = y1)#25\n",
    "train1 = pd.concat([X1_train, y1_train], axis=1)\n",
    "test1=pd.concat([X1_test, y1_test], axis=1)\n",
    "\n",
    "X2=df2[['checkAccStatus', 'durationMth', 'credHist', 'purpose', 'credAmt',\n",
    "       'savAccBond', 'emplySince', 'instRate', 'personalStatSex',\n",
    "       'otherDebtGuar', 'presResSince', 'prpty', 'age(years)',\n",
    "       'otherInstallPlans', 'housing', 'numExistCreds', 'job',\n",
    "       'numPplMaintain', 'telephone', 'frgnWorker']]\n",
    "y2=df2[[\"goodBad\"]]\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, random_state=25, test_size=0.2, stratify = y2)#25\n",
    "train2 = pd.concat([X2_train, y2_train], axis=1)\n",
    "test2=pd.concat([X2_test, y2_test], axis=1)\n",
    "\n",
    "X3=df3[['age', 'sex', 'chest pain type', 'resting blood pressure',\n",
    "       'serum cholesterol (mg/dl)', 'resting blood sugar >120mg/dl',\n",
    "       'resting electrocariographic results', 'maximum heart rate received',\n",
    "       'exercise induced angina', 'oldpeak', 'slopePeak', 'numMajorVessels',\n",
    "       'thal']]\n",
    "y3=df3[[\"class\"]]\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, random_state=25, test_size=0.2, stratify = y3)#25\n",
    "train3 = pd.concat([X3_train, y3_train], axis=1)\n",
    "test3=pd.concat([X3_test, y3_test], axis=1)\n",
    "\n",
    "X4=df4[[ 'age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps',\n",
    "       'deg-malig', 'breast', 'breast-quad', 'irradiat']]\n",
    "y4=df4[['class']]\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, random_state=25, test_size=0.2, stratify = y4)#25\n",
    "train4 = pd.concat([X4_train, y4_train], axis=1)\n",
    "test4=pd.concat([X4_test, y4_test], axis=1)\n",
    "\n",
    "X5=df5[['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
    "       'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20']]\n",
    "y5=df5[[\"class\"]]\n",
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, random_state=25, test_size=0.2, stratify = y5)#25\n",
    "train5 = pd.concat([X5_train, y5_train], axis=1)\n",
    "test5=pd.concat([X5_test, y5_test], axis=1)\n",
    "\n",
    "\n",
    "X6=df6[['id',\n",
    " 'gender',\n",
    " 'age',\n",
    " 'hypertension',\n",
    " 'heart_disease',\n",
    " 'ever_married',\n",
    " 'work_type',\n",
    " 'Residence_type',\n",
    " 'avg_glucose_level',\n",
    " 'bmi',\n",
    " 'smoking_status']]\n",
    "y6=df6[['stroke']]\n",
    "X6_train, X6_test, y6_train, y6_test = train_test_split(X6, y6, random_state=25, test_size=0.2, stratify = y6)#25\n",
    "train6 = pd.concat([X6_train, y6_train], axis=1)\n",
    "test6=pd.concat([X6_test, y6_test], axis=1)\n",
    "\n",
    "X7=df7[['gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s',\n",
    "       'degree_p', 'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p']]\n",
    "y7=df7[['status']]\n",
    "X7_train, X7_test, y7_train, y7_test = train_test_split(X7, y7, random_state=25, test_size=0.2, stratify = y7)#25\n",
    "train7 = pd.concat([X7_train, y7_train], axis=1)\n",
    "test7=pd.concat([X7_test, y7_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gender', 'ssc_p', 'ssc_b', 'hsc_p', 'hsc_b', 'hsc_s', 'degree_p',\n",
       "       'degree_t', 'workex', 'etest_p', 'specialisation', 'mba_p'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X7.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7[\"status\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_train=np_utils.to_categorical(y1_train,num_classes=3)\n",
    "y1_test=np_utils.to_categorical(y1_test,num_classes=3)\n",
    "\n",
    "\n",
    "y2_train=np_utils.to_categorical(y2_train,num_classes=2)\n",
    "y2_test=np_utils.to_categorical(y2_test,num_classes=2)\n",
    "\n",
    "\n",
    "y3_train=np_utils.to_categorical(y3_train,num_classes=2)\n",
    "y3_test=np_utils.to_categorical(y3_test,num_classes=2)\n",
    "\n",
    "y4_train=np_utils.to_categorical(y4_train,num_classes=2)\n",
    "y4_test=np_utils.to_categorical(y4_test,num_classes=2)\n",
    "\n",
    "y5_train=np_utils.to_categorical(y5_train,num_classes=3)\n",
    "y5_test=np_utils.to_categorical(y5_test,num_classes=3)\n",
    "\n",
    "y6_train=np_utils.to_categorical(y6_train,num_classes=2)\n",
    "y6_test=np_utils.to_categorical(y6_test,num_classes=2)\n",
    "\n",
    "y7_train=np_utils.to_categorical(y7_train,num_classes=2)\n",
    "y7_test=np_utils.to_categorical(y7_test,num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL CREATION AND TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(1000,input_dim=4,activation='relu'))\n",
    "model.add(Dense(500,activation='relu'))\n",
    "model.add(Dense(300,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "6/6 [==============================] - 1s 9ms/step - loss: 0.9649 - accuracy: 0.4680\n",
      "Epoch 2/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5328 - accuracy: 0.7286\n",
      "Epoch 3/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.4286 - accuracy: 0.7320\n",
      "Epoch 4/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3148 - accuracy: 0.8768\n",
      "Epoch 5/50\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 0.3418 - accuracy: 0.7781\n",
      "Epoch 6/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1868 - accuracy: 0.9598\n",
      "Epoch 7/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1561 - accuracy: 0.9642\n",
      "Epoch 8/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1164 - accuracy: 0.9649\n",
      "Epoch 9/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1763 - accuracy: 0.9173\n",
      "Epoch 10/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1257 - accuracy: 0.9615\n",
      "Epoch 11/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.1177 - accuracy: 0.9399\n",
      "Epoch 12/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0765 - accuracy: 0.9823\n",
      "Epoch 13/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0674 - accuracy: 0.9835\n",
      "Epoch 14/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0727 - accuracy: 0.9710\n",
      "Epoch 15/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0801 - accuracy: 0.9725\n",
      "Epoch 16/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0510 - accuracy: 0.9906\n",
      "Epoch 17/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0927 - accuracy: 0.9536\n",
      "Epoch 18/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0506 - accuracy: 0.9873\n",
      "Epoch 19/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0919 - accuracy: 0.9598\n",
      "Epoch 20/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0489 - accuracy: 0.9896\n",
      "Epoch 21/50\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.97 - 0s 12ms/step - loss: 0.0835 - accuracy: 0.9790\n",
      "Epoch 22/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1061 - accuracy: 0.9775\n",
      "Epoch 23/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0366 - accuracy: 0.9962\n",
      "Epoch 24/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0557 - accuracy: 0.9920\n",
      "Epoch 25/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.9858\n",
      "Epoch 26/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0655 - accuracy: 0.9733\n",
      "Epoch 27/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1079 - accuracy: 0.9707\n",
      "Epoch 28/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0598 - accuracy: 0.9885\n",
      "Epoch 29/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.0469 - accuracy: 0.9920\n",
      "Epoch 30/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0935 - accuracy: 0.9626\n",
      "Epoch 31/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0313 - accuracy: 0.9976\n",
      "Epoch 32/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1232 - accuracy: 0.9574\n",
      "Epoch 33/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.1425 - accuracy: 0.9455\n",
      "Epoch 34/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.1207 - accuracy: 0.9480\n",
      "Epoch 35/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0769 - accuracy: 0.9648\n",
      "Epoch 36/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0817 - accuracy: 0.9749\n",
      "Epoch 37/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0733 - accuracy: 0.9808\n",
      "Epoch 38/50\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 0.1024 - accuracy: 0.9701\n",
      "Epoch 39/50\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.95 - 0s 12ms/step - loss: 0.0577 - accuracy: 0.9604\n",
      "Epoch 40/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0445 - accuracy: 0.9920\n",
      "Epoch 41/50\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.0351 - accuracy: 0.9962\n",
      "Epoch 42/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1074 - accuracy: 0.9618\n",
      "Epoch 43/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.0534 - accuracy: 0.9805\n",
      "Epoch 44/50\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.0359 - accuracy: 0.9906\n",
      "Epoch 45/50\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.0976 - accuracy: 0.9737\n",
      "Epoch 46/50\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 0.0362 - accuracy: 0.9858\n",
      "Epoch 47/50\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0649 - accuracy: 0.9885\n",
      "Epoch 48/50\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.0378 - accuracy: 0.9938\n",
      "Epoch 49/50\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1017 - accuracy: 0.9757\n",
      "Epoch 50/50\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.0526 - accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1713a119608>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X1_train,y1_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the iris dataset 93.33333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(X1_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y1_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the iris dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=Sequential()\n",
    "model2.add(Dense(1000,input_dim=20,activation='relu'))\n",
    "model2.add(Dense(500,activation='relu'))\n",
    "model2.add(Dense(300,activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "model2.add(Dense(2,activation='softmax'))\n",
    "model2.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 1s 6ms/step - loss: 94.8814 - accuracy: 0.5834\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 12.0323 - accuracy: 0.5960\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 4.7706 - accuracy: 0.5642\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 3.6942 - accuracy: 0.4988\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.7814 - accuracy: 0.5941\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.4976 - accuracy: 0.5715\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.4522 - accuracy: 0.5298\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.7762 - accuracy: 0.5739\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 1.3624 - accuracy: 0.5871\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 1.2581 - accuracy: 0.5870\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6553 - accuracy: 0.7078\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6197 - accuracy: 0.6999\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6082 - accuracy: 0.7049\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6186 - accuracy: 0.6921\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6178 - accuracy: 0.6914\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6214 - accuracy: 0.6874\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6104 - accuracy: 0.7022\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6132 - accuracy: 0.6979\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.6820\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6322 - accuracy: 0.6750\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6063 - accuracy: 0.7058\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6141 - accuracy: 0.6971\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6113 - accuracy: 0.6990\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6078 - accuracy: 0.7043\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5986 - accuracy: 0.7156\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6119 - accuracy: 0.7000\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6232 - accuracy: 0.6846\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6069 - accuracy: 0.7055\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6156 - accuracy: 0.6933\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6100 - accuracy: 0.7020\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.6008 - accuracy: 0.7117\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5938 - accuracy: 0.7218\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6053 - accuracy: 0.7073\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6141 - accuracy: 0.6989\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5858 - accuracy: 0.7291\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6230 - accuracy: 0.6860\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6121 - accuracy: 0.6978\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5773 - accuracy: 0.7343\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6174 - accuracy: 0.6938\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5976 - accuracy: 0.7162\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5965 - accuracy: 0.7172\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6200 - accuracy: 0.6899\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5747 - accuracy: 0.7455\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6048 - accuracy: 0.7057\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 0.6288 - accuracy: 0.6790\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6063 - accuracy: 0.7060\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.6042 - accuracy: 0.7082\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 0s 9ms/step - loss: 0.6089 - accuracy: 0.7012\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 0s 8ms/step - loss: 0.5927 - accuracy: 0.7230\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 0s 7ms/step - loss: 0.5982 - accuracy: 0.7157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17130016348>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(X2_train,y2_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the german dataset 70.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82       140\n",
      "           1       0.00      0.00      0.00        60\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.35      0.50      0.41       200\n",
      "weighted avg       0.49      0.70      0.58       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sim Shi Qian\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sim Shi Qian\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sim Shi Qian\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "prediction=model2.predict(X2_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y2_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the german dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=Sequential()\n",
    "model3.add(Dense(1000,input_dim=13,activation='relu'))\n",
    "model3.add(Dense(500,activation='relu'))\n",
    "model3.add(Dense(300,activation='relu'))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(Dense(2,activation='softmax'))\n",
    "model3.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 1s 8ms/step - loss: 22.2120 - accuracy: 0.4180\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 7.6991 - accuracy: 0.4310\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.6160 - accuracy: 0.5551\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.7896 - accuracy: 0.4979\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.3163 - accuracy: 0.5041\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7540 - accuracy: 0.6556\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7265 - accuracy: 0.5996\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.8263 - accuracy: 0.5911\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.6250 - accuracy: 0.6824\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7296 - accuracy: 0.6680\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.6612 - accuracy: 0.6868\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.6048 - accuracy: 0.7043\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.6311 - accuracy: 0.6672\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5618 - accuracy: 0.7063\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5126 - accuracy: 0.7742\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5526 - accuracy: 0.7333\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5092 - accuracy: 0.7182\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5562 - accuracy: 0.7085\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.5227 - accuracy: 0.7533\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5071 - accuracy: 0.7668\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4706 - accuracy: 0.7324\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.5217 - accuracy: 0.7349\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5045 - accuracy: 0.7500\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5747 - accuracy: 0.6977\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.7040 - accuracy: 0.6309\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.7474 - accuracy: 0.6374\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5749 - accuracy: 0.7021\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4985 - accuracy: 0.7341\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5122 - accuracy: 0.7691\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.4759 - accuracy: 0.7681\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4980 - accuracy: 0.7568\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.5687 - accuracy: 0.7176\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4058 - accuracy: 0.8084\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4355 - accuracy: 0.8301\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.5227 - accuracy: 0.7435\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4721 - accuracy: 0.7868\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4214 - accuracy: 0.8116\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4195 - accuracy: 0.8090\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.4782 - accuracy: 0.7922\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.4215 - accuracy: 0.7927\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.5827 - accuracy: 0.6975\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.4572 - accuracy: 0.7833\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.4400 - accuracy: 0.8074\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4429 - accuracy: 0.7918\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.4544 - accuracy: 0.7738\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.3835 - accuracy: 0.8210\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.3927 - accuracy: 0.8192\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4223 - accuracy: 0.7660\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.4210 - accuracy: 0.8530\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.3709 - accuracy: 0.8324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1712e8cf788>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(X3_train,y3_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the heart dataset 85.18518518518519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        30\n",
      "           1       0.90      0.75      0.82        24\n",
      "\n",
      "    accuracy                           0.85        54\n",
      "   macro avg       0.86      0.84      0.85        54\n",
      "weighted avg       0.86      0.85      0.85        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=model3.predict(X3_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y3_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the heart dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4=Sequential()\n",
    "model4.add(Dense(1000,input_dim=9,activation='relu'))\n",
    "model4.add(Dense(500,activation='relu'))\n",
    "model4.add(Dense(300,activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(Dense(2,activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 1s 7ms/step - loss: 0.7175 - accuracy: 0.6034\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5357 - accuracy: 0.7568\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4771 - accuracy: 0.7824\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.5219 - accuracy: 0.7072\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5119 - accuracy: 0.7275\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.5113 - accuracy: 0.7125\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.5279 - accuracy: 0.7496\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4805 - accuracy: 0.7445\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4772 - accuracy: 0.7703\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4225 - accuracy: 0.7918\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4696 - accuracy: 0.7811\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.7816\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4373 - accuracy: 0.7757\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3966 - accuracy: 0.8471\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4208 - accuracy: 0.8149\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.4326 - accuracy: 0.7765\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4296 - accuracy: 0.8156\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4264 - accuracy: 0.8185\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3575 - accuracy: 0.8440\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 0.3828 - accuracy: 0.8065\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3652 - accuracy: 0.8012\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.4233 - accuracy: 0.7915\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.3236 - accuracy: 0.8697\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.2806 - accuracy: 0.8731\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.3063 - accuracy: 0.8675\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2969 - accuracy: 0.8725\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2702 - accuracy: 0.8686\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2655 - accuracy: 0.8816\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.2715 - accuracy: 0.8797\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1931 - accuracy: 0.9104\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1947 - accuracy: 0.9174\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2557 - accuracy: 0.8912\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2303 - accuracy: 0.8753\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.2336 - accuracy: 0.8743\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.2430 - accuracy: 0.8809\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2479 - accuracy: 0.8958\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.1800 - accuracy: 0.9274\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1808 - accuracy: 0.9066\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.2277 - accuracy: 0.9082\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.2236 - accuracy: 0.8929\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1690 - accuracy: 0.9267\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 0.1555 - accuracy: 0.9320\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1192 - accuracy: 0.9526\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.1078 - accuracy: 0.9476\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1286 - accuracy: 0.9246\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.1353 - accuracy: 0.9298\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1734 - accuracy: 0.9351\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.1105 - accuracy: 0.9565\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1556 - accuracy: 0.9510\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.1267 - accuracy: 0.9503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1712632da88>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(X4_train,y4_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the cancer dataset 68.42105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.80        40\n",
      "           1       0.40      0.12      0.18        17\n",
      "\n",
      "    accuracy                           0.68        57\n",
      "   macro avg       0.56      0.52      0.49        57\n",
      "weighted avg       0.62      0.68      0.62        57\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=model4.predict(X4_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y4_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the cancer dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=Sequential()\n",
    "model5.add(Dense(1000,input_dim=21,activation='relu'))\n",
    "model5.add(Dense(500,activation='relu'))\n",
    "model5.add(Dense(300,activation='relu'))\n",
    "model5.add(Dropout(0.2))\n",
    "model5.add(Dense(3,activation='softmax'))\n",
    "model5.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "200/200 [==============================] - 3s 6ms/step - loss: 0.5073 - accuracy: 0.7719\n",
      "Epoch 2/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3540 - accuracy: 0.8353\n",
      "Epoch 3/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3175 - accuracy: 0.8430\n",
      "Epoch 4/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.3370 - accuracy: 0.8386\n",
      "Epoch 5/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3058 - accuracy: 0.8560\n",
      "Epoch 6/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2840 - accuracy: 0.8674\n",
      "Epoch 7/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.3017 - accuracy: 0.8537\n",
      "Epoch 8/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2874 - accuracy: 0.8601\n",
      "Epoch 9/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2925 - accuracy: 0.8608\n",
      "Epoch 10/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2738 - accuracy: 0.8716\n",
      "Epoch 11/50\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.2535 - accuracy: 0.8769\n",
      "Epoch 12/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.2462 - accuracy: 0.8801\n",
      "Epoch 13/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2440 - accuracy: 0.8906\n",
      "Epoch 14/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.2310 - accuracy: 0.8889\n",
      "Epoch 15/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2140 - accuracy: 0.8978\n",
      "Epoch 16/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2195 - accuracy: 0.8935\n",
      "Epoch 17/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2130 - accuracy: 0.8954\n",
      "Epoch 18/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.2091 - accuracy: 0.9016\n",
      "Epoch 19/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1827 - accuracy: 0.9136\n",
      "Epoch 20/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1759 - accuracy: 0.9138\n",
      "Epoch 21/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1806 - accuracy: 0.9199\n",
      "Epoch 22/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1752 - accuracy: 0.9205\n",
      "Epoch 23/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1634 - accuracy: 0.9267\n",
      "Epoch 24/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1573 - accuracy: 0.9295\n",
      "Epoch 25/50\n",
      "200/200 [==============================] - 1s 7ms/step - loss: 0.1710 - accuracy: 0.9168\n",
      "Epoch 26/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.1246 - accuracy: 0.9431 \n",
      "Epoch 27/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1137 - accuracy: 0.9542\n",
      "Epoch 28/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1583 - accuracy: 0.9257\n",
      "Epoch 29/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1257 - accuracy: 0.9441\n",
      "Epoch 30/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.1127 - accuracy: 0.9509\n",
      "Epoch 31/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0989 - accuracy: 0.9570\n",
      "Epoch 32/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0694 - accuracy: 0.9729\n",
      "Epoch 33/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0858 - accuracy: 0.9708\n",
      "Epoch 34/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.1047 - accuracy: 0.9578\n",
      "Epoch 35/50\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.0624 - accuracy: 0.97 - 2s 9ms/step - loss: 0.0625 - accuracy: 0.9761\n",
      "Epoch 36/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0561 - accuracy: 0.9781\n",
      "Epoch 37/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0897 - accuracy: 0.9660\n",
      "Epoch 38/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0598 - accuracy: 0.9795\n",
      "Epoch 39/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0551 - accuracy: 0.9814\n",
      "Epoch 40/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0468 - accuracy: 0.9818\n",
      "Epoch 41/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0704 - accuracy: 0.9749\n",
      "Epoch 42/50\n",
      "200/200 [==============================] - 2s 8ms/step - loss: 0.0392 - accuracy: 0.9846\n",
      "Epoch 43/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0179 - accuracy: 0.9941\n",
      "Epoch 44/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0331 - accuracy: 0.9881\n",
      "Epoch 45/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0685 - accuracy: 0.9800\n",
      "Epoch 46/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0654 - accuracy: 0.9760\n",
      "Epoch 47/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0789 - accuracy: 0.9743\n",
      "Epoch 48/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0244 - accuracy: 0.9903\n",
      "Epoch 49/50\n",
      "200/200 [==============================] - 2s 10ms/step - loss: 0.0361 - accuracy: 0.9843\n",
      "Epoch 50/50\n",
      "200/200 [==============================] - 2s 9ms/step - loss: 0.0327 - accuracy: 0.9913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17131a3ff48>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X5_train,y5_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the wave dataset 84.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       332\n",
      "           1       0.89      0.82      0.85       329\n",
      "           2       0.84      0.85      0.85       339\n",
      "\n",
      "    accuracy                           0.84      1000\n",
      "   macro avg       0.84      0.84      0.84      1000\n",
      "weighted avg       0.84      0.84      0.84      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=model5.predict(X5_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y5_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the wave dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6=Sequential()\n",
    "model6.add(Dense(1000,input_dim=11,activation='relu'))\n",
    "model6.add(Dense(500,activation='relu'))\n",
    "model6.add(Dense(300,activation='relu'))\n",
    "model6.add(Dropout(0.2))\n",
    "model6.add(Dense(2,activation='softmax'))\n",
    "model6.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "205/205 [==============================] - 4s 8ms/step - loss: nan - accuracy: 0.9410\n",
      "Epoch 2/50\n",
      "205/205 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.9550\n",
      "Epoch 3/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9498\n",
      "Epoch 4/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9496\n",
      "Epoch 5/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9515\n",
      "Epoch 6/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9536\n",
      "Epoch 7/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9509\n",
      "Epoch 8/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9482\n",
      "Epoch 9/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9502\n",
      "Epoch 10/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9541\n",
      "Epoch 11/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9506\n",
      "Epoch 12/50\n",
      "205/205 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.9558\n",
      "Epoch 13/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9533\n",
      "Epoch 14/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9513\n",
      "Epoch 15/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9507\n",
      "Epoch 16/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9559\n",
      "Epoch 17/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9495\n",
      "Epoch 18/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9548\n",
      "Epoch 19/50\n",
      "205/205 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.9548\n",
      "Epoch 20/50\n",
      "205/205 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.9543\n",
      "Epoch 21/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9525\n",
      "Epoch 22/50\n",
      "205/205 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.9519\n",
      "Epoch 23/50\n",
      "205/205 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.9533\n",
      "Epoch 24/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9557\n",
      "Epoch 25/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9434\n",
      "Epoch 26/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9543\n",
      "Epoch 27/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9483\n",
      "Epoch 28/50\n",
      "205/205 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.9492\n",
      "Epoch 29/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9554\n",
      "Epoch 30/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9528\n",
      "Epoch 31/50\n",
      "205/205 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.9537\n",
      "Epoch 32/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9498\n",
      "Epoch 33/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9503\n",
      "Epoch 34/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9489\n",
      "Epoch 35/50\n",
      "205/205 [==============================] - 1s 6ms/step - loss: nan - accuracy: 0.9485\n",
      "Epoch 36/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9426\n",
      "Epoch 37/50\n",
      "205/205 [==============================] - 1s 7ms/step - loss: nan - accuracy: 0.9527\n",
      "Epoch 38/50\n",
      "205/205 [==============================] - ETA: 0s - loss: nan - accuracy: 0.946 - 1s 7ms/step - loss: nan - accuracy: 0.9469\n",
      "Epoch 39/50\n",
      "205/205 [==============================] - 2s 10ms/step - loss: nan - accuracy: 0.9496\n",
      "Epoch 40/50\n",
      "205/205 [==============================] - 2s 10ms/step - loss: nan - accuracy: 0.9527\n",
      "Epoch 41/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9463\n",
      "Epoch 42/50\n",
      "205/205 [==============================] - 2s 7ms/step - loss: nan - accuracy: 0.9531\n",
      "Epoch 43/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9507\n",
      "Epoch 44/50\n",
      "205/205 [==============================] - 2s 10ms/step - loss: nan - accuracy: 0.9514\n",
      "Epoch 45/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9537\n",
      "Epoch 46/50\n",
      "205/205 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.9520\n",
      "Epoch 47/50\n",
      "205/205 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.9515\n",
      "Epoch 48/50\n",
      "205/205 [==============================] - 2s 9ms/step - loss: nan - accuracy: 0.9438A: 1s - loss: nan - accuracy - ETA: 1s - loss: nan - \n",
      "Epoch 49/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9558\n",
      "Epoch 50/50\n",
      "205/205 [==============================] - 2s 8ms/step - loss: nan - accuracy: 0.9469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1713e322b48>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(X6_train,y6_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the stroke dataset 95.10763209393346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97       972\n",
      "           1       0.00      0.00      0.00        50\n",
      "\n",
      "    accuracy                           0.95      1022\n",
      "   macro avg       0.48      0.50      0.49      1022\n",
      "weighted avg       0.90      0.95      0.93      1022\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sim Shi Qian\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sim Shi Qian\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Sim Shi Qian\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "prediction=model6.predict(X6_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y6_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the stroke dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7=Sequential()\n",
    "model7.add(Dense(1000,input_dim=12,activation='relu'))\n",
    "model7.add(Dense(500,activation='relu'))\n",
    "model7.add(Dense(300,activation='relu'))\n",
    "model7.add(Dropout(0.2))\n",
    "model7.add(Dense(2,activation='softmax'))\n",
    "model7.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 1s 7ms/step - loss: 5.6458 - accuracy: 0.5895\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 2.4217 - accuracy: 0.6792\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.9311 - accuracy: 0.6493\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0427 - accuracy: 0.6841\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 1.0452 - accuracy: 0.7250\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6421 - accuracy: 0.7296\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.6371 - accuracy: 0.7318\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5797 - accuracy: 0.6967\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5974 - accuracy: 0.6595\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4495 - accuracy: 0.7656\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4333 - accuracy: 0.8041\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.5529 - accuracy: 0.7220\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.4795 - accuracy: 0.7351\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5455 - accuracy: 0.7654\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3984 - accuracy: 0.8193\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.4700 - accuracy: 0.7749\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3831 - accuracy: 0.8599\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3619 - accuracy: 0.8406\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3362 - accuracy: 0.8744\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4434 - accuracy: 0.7940\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.5193 - accuracy: 0.7705\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.4872 - accuracy: 0.7927\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3904 - accuracy: 0.8325\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3954 - accuracy: 0.8394\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3979 - accuracy: 0.8350\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.4124 - accuracy: 0.8170\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3764 - accuracy: 0.8202\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3552 - accuracy: 0.8023\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.2852 - accuracy: 0.8629\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3395 - accuracy: 0.8475\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3023 - accuracy: 0.8795\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3885 - accuracy: 0.8360\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 10ms/step - loss: 0.3903 - accuracy: 0.8249\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3407 - accuracy: 0.8439\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3557 - accuracy: 0.8439\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3038 - accuracy: 0.8805\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.4059 - accuracy: 0.8154\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3558 - accuracy: 0.8539\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3155 - accuracy: 0.8818\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.4225 - accuracy: 0.8048\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.3482 - accuracy: 0.8286\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3689 - accuracy: 0.8575\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.8364\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3750 - accuracy: 0.8068\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3499 - accuracy: 0.8163\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 0.3705 - accuracy: 0.8569\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3433 - accuracy: 0.8881\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 12ms/step - loss: 0.3200 - accuracy: 0.8345\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 14ms/step - loss: 0.2815 - accuracy: 0.8704\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.3717 - accuracy: 0.8224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17138679bc8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7.fit(X7_train,y7_train,batch_size=20,epochs=50,verbose=1)  #removed validation_data=(X1_test,y1_test) for test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the placement dataset 90.69767441860465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        13\n",
      "           1       0.93      0.93      0.93        30\n",
      "\n",
      "    accuracy                           0.91        43\n",
      "   macro avg       0.89      0.89      0.89        43\n",
      "weighted avg       0.91      0.91      0.91        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction=model7.predict(X7_test)\n",
    "length=len(prediction)\n",
    "y_label=np.argmax(y7_test,axis=1)\n",
    "predict_label=np.argmax(prediction,axis=1)\n",
    "\n",
    "accuracy=np.sum(y_label==predict_label)/length * 100 \n",
    "print(\"Accuracy of the placement dataset\",accuracy )\n",
    "print(classification_report(y_label,predict_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
