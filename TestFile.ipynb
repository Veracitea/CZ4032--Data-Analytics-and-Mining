{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TestFile.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"VkEmLVJzPKBy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634270943052,"user_tz":-480,"elapsed":24413,"user":{"displayName":"Quek Lin Hui","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17115276251661789309"}},"outputId":"c1622c8b-2d74-4379-91f5-492d578c5b76"},"source":["!pip install matplotlib\n","!pip install unlzw\n","!pip install pyarc"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n","Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.19.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib) (1.15.0)\n","Collecting unlzw\n","  Downloading unlzw-0.1.1.tar.gz (36 kB)\n","Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from unlzw) (1.14.6)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0.0->unlzw) (2.20)\n","Building wheels for collected packages: unlzw\n","  Building wheel for unlzw (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for unlzw: filename=unlzw-0.1.1-cp37-cp37m-linux_x86_64.whl size=21441 sha256=9aa16bb1cb4dacca7429a0ddd161ae8551d48d681000c302f3a9e6fd01d8e13c\n","  Stored in directory: /root/.cache/pip/wheels/6e/36/71/0956632d0fc14c99edc168063b7ff06c3462e19855a0df36db\n","Successfully built unlzw\n","Installing collected packages: unlzw\n","Successfully installed unlzw-0.1.1\n","Collecting pyarc\n","  Downloading pyarc-1.1.4-py2.py3-none-any.whl (36 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyarc) (1.19.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pyarc) (1.1.5)\n","Collecting pyfim\n","  Downloading pyfim-6.28.tar.gz (357 kB)\n","\u001b[K     |████████████████████████████████| 357 kB 39.2 MB/s \n","\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyarc) (0.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pyarc) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pyarc) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pyarc) (1.15.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->pyarc) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->pyarc) (1.0.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->pyarc) (1.4.1)\n","Building wheels for collected packages: pyfim\n","  Building wheel for pyfim (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyfim: filename=pyfim-6.28-cp37-cp37m-linux_x86_64.whl size=537774 sha256=430da3a6d63c37fd7d21bf67e0ecb3dad321d09ec62ca74387b5eb14508da962\n","  Stored in directory: /root/.cache/pip/wheels/08/9f/26/09cb4efd027e46f96e0a0f33d0a74be614d3caf89c1eeb75a8\n","Successfully built pyfim\n","Installing collected packages: pyfim, pyarc\n","Successfully installed pyarc-1.1.4 pyfim-6.28\n"]}]},{"cell_type":"code","metadata":{"id":"XgrhZXwCPQrM","executionInfo":{"status":"ok","timestamp":1634270944681,"user_tz":-480,"elapsed":266,"user":{"displayName":"Quek Lin Hui","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17115276251661789309"}}},"source":["import matplotlib.pyplot as plt\n","from sklearn import tree\n","import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split\n","from unlzw import unlzw\n","import csv, re\n","from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n","from pyarc import TransactionDB\n","from pyarc.algorithms import (\n","    top_rules,\n","    createCARs,\n","    M1Algorithm,\n","    M2Algorithm\n",")\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8bgIw3CHJYYZ","executionInfo":{"status":"ok","timestamp":1634271101998,"user_tz":-480,"elapsed":29949,"user":{"displayName":"Quek Lin Hui","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17115276251661789309"}},"outputId":"51473e8e-3c06-4a9c-f3d9-80dfcfce5880"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"Q_CSsgUuZ8bu"},"source":["#Data Preprocessing"]},{"cell_type":"code","metadata":{"id":"fOot6z2pPZYN","executionInfo":{"status":"ok","timestamp":1634271297860,"user_tz":-480,"elapsed":1073,"user":{"displayName":"Quek Lin Hui","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17115276251661789309"}}},"source":["# Load the iris dataset\n","# iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)\n","iris = pd.read_csv('drive/MyDrive/iris.data', header = None)\n","iris.columns=[\"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\", \"Class\"]\n","iris.to_csv(\"iris.csv\", index = None, header = True)\n","#iris = pd.read_csv('iris.csv',index= None, header = True)\n","\n","#Load the waveform dataset #CART decision tree algorithm: 72% (Information from the .names file)\n","with open('drive/MyDrive/waveform.data.Z', 'rb') as fh:\n","    compressed_data = fh.read()\n","    uncompressed_data = unlzw(compressed_data)\n","data = uncompressed_data.decode('utf-8').splitlines()\n","with open(\"wave.csv\", \"w\") as csv_file:\n","    writer = csv.writer(csv_file, delimiter = '\\t')\n","    for line in data:\n","        writer.writerow(re.split('\\s+',line))\n","wave = pd.read_csv('wave.csv', header = None)\n","wave.to_csv(\"wave.csv\", index = None, header = True)\n","wave_labels = []\n","for i in range(21):\n","  wave_labels.append('x'+str(i))\n","wave_labels.append('class')\n","wave.columns=wave_labels\n","wave.to_csv(\"wave.csv\", index = None, header = True)\n","\n","#Load the breast cancer dataset\n","breastCancer = pd.read_csv(\"drive/MyDrive/breast-cancer.data\")\n","breastCancer.columns=[\"class\",\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\",\"deg-malig\",\"breast\",\"breast-quad\",\"irradiat\"]\n","breastCancer.to_csv(\"breastCancer.csv\", index = None, header = True)\n","#wave.to_csv(\"breastCancer.csv\", index = None, header = True)\n","\n","\n","#Load the german dataset\n","german = pd.read_csv('drive/MyDrive/german.data', header = None)\n","german.head()\n","german_columns=[\"checkAccStatus\", \"durationMth\", \"credHist\", \"purpose\", \"credAmt\",\"savAccBond\",\"emplySince\",\"instRate\",\"personalStatSex\",\"otherDebtGuar\",\"presResSince\",\"prpty\",\"age(years)\",\"otherInstallPlans\",\"housing\",\"numExistCreds\",\"job\",\"numPplMaintain\",\"telephone\",\"frgnWorker\",\"goodBad\"]\n","german = german[0].str.split(\" \", n = 20, expand = True)\n","german.columns = german_columns\n","german.to_csv(\"german.csv\", index = None, header = True)\n","#german.columns = german_columns\n","\n","#Load the heart dataset\n","heart = pd.read_csv('drive/MyDrive/heart.dat', header = None)\n","heart = heart[0].str.split(\" \", n = 13, expand = True)\n","heart.columns=[\"age\", \"sex\", \"chest pain type\", \"resting blood pressure\", \"serum cholesterol (mg/dl)\", \"resting blood sugar >120mg/dl\",\"resting electrocariographic results\",\"maximum heart rate received\",\"exercise induced angina\", \"oldpeak\",\"slopePeak\", \"numMajorVessels\",\"thal\",\"class\"]\n","heart_columns= [\"age\", \"sex\", \"chest pain type\", \"resting blood pressure\", \"serum cholesterol (mg/dl)\", \"resting blood sugar >120mg/dl\",\"resting electrocariographic results\",\"maximum heart rate received\",\"exercise induced angina\", \"oldpeak\",\"slopePeak\", \"numMajorVessels\",\"thal\"]\n","heart.to_csv(\"heart.csv\", index = None, header = True)\n","\n","\n","#Load the kaggle dataset\n","#stroke\n","stroke = pd.read_csv(\"drive/MyDrive/CZ4032DAM/datasets/healthcare-dataset-stroke-data.csv\", sep=\";\", index_col=0)\n","\n","#Heart Attack\n","campusPlacement = pd.read_csv(\"drive/MyDrive/CZ4032DAM/datasets/Placement_Data_Full_Class.csv\", sep=\";\", index_col=0)\n"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RA_lZ2P8aEiw"},"source":["#2) Implement an algorithm of Classification based on Association rules. You can implement any algorithm in the paper, or a variant of these algorithms"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lg-Vmn7ha0Dq","executionInfo":{"status":"ok","timestamp":1633487810357,"user_tz":-480,"elapsed":272,"user":{"displayName":"Quek Lin Hui","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17115276251661789309"}},"outputId":"9ac4e281-de79-4bec-f75a-6dc91e8e88c9"},"source":["#TODO: split the train and test properly\n","data_train = pd.read_csv(\"iris.csv\")\n","data_test = pd.read_csv(\"iris.csv\")\n","\n","txns_train = TransactionDB.from_DataFrame(data_train)\n","txns_test = TransactionDB.from_DataFrame(data_test)\n","\n","# get the best association rules\n","rules = top_rules(txns_train.string_representation)\n","\n","# convert them to class association rules\n","cars = createCARs(rules)\n","\n","#classifier = M1Algorithm(cars, txns_train).build()\n","classifier = M2Algorithm(cars, txns_train).build()\n","\n","iris_accuracy = classifier.test_transactions(txns_test)\n","print(iris_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.9933333333333333\n"]}]},{"cell_type":"code","metadata":{"id":"U6xbjLGoY-04"},"source":[""],"execution_count":null,"outputs":[]}]}